# EfficientNet LibTorch

EfficientNet model implementation using `libtorch` ([PyTorch][pytorch] C++ sources) with Python/C++ bindings.

[pytorch]: https://github.com/pytorch/pytorch

- [Build and Install](#build-and-install)
- [Usage](#usage)
- [Debugging Compilation Problems](#debugging-compilation-problems)
  - [Missing or Wrong CMake](#missing-or-wrong-cmake)
  - [Failed to compute shorthash](#failed-to-compute-shorthash)
- [Debugging Runtime Errors](#debugging-runtime-errors)
  - [ImportError `generic_type` with Unknown Reference](#importerror-generic_type-with-unknown-reference)
  - [Unrecognized Symbol Error](#unrecognized-symbol-error)

## Build and Install

To install the package, you must first build the dependencies.
You will need to define the paths to the relevant libraries compiled for your system:

| Variable           | Description                                               |
| ------------------ | --------------------------------------------------------- |
| PYTORCH_DIR        | Installation path of the Torch C++ library compiled from sources (or precompiled matching your system).  |
| PYBIND11_DIR       | Installation path of PyBind11 library <br> (hint: can reuse PyTorch's `third_party` submodule)           |
| PYTHON_EXECUTABLE  | Path to the Python binary to find dependencies, headers and other references. <br> (RECOMMENDED: use virtual environment, e.g.: `conda`)   |

**Hint**
Sources of [pytorch] provide a `setup.py` script that helps build and install C++ libraries by wrapping CMake and Ninja.
A similar procedure is used for this repository extensions.

**Note**
To have GPU-enabled runtime, make sure that PyTorch and EfficientNet libraries all find references to CUDA/cuDNN.

Once the above variables where defined, you must activate your environment, and then install the package.
This process has been simplified by wrapping the C++ Extension with `CMake` through the `setup.py`.

``` shell
conda activate <myenv>
python setup.py install
```

Installation of the packages in the activated environment will be processed. If any problem occurs, refer
to the logs to find missing pieces of information (often it is due to a missing or not found path).

If everything succeeded, you should be able to move on to using the package.


## Usage

Once the package was built and installed, it can be called directly in Python.

You can test that references are found correctly using for exemple the following code:

``` shell
â¯ python
Python 3.7.7 (default, May  7 2020, 21:25:33)
[GCC 7.3.0] :: Anaconda, Inc. on linux
Type "help", "copyright", "credits" or "license" for more information.

>>> import efficientnet_libtorch
>>> efficientnet_libtorch.activation.swish
<built-in method swish of PyCapsule object at 0x7f109a3eecf0>
>>>
```

## Development notes

### Precompiled headers

Every `*.cpp` file must start with these two lines (including before any comment):

    #include "stdafx.h"
    #pragma hdrstop

This ensures the file uses precompiled headers and includes basic required dependencies (`Windows.h`) and defines
when corresponding platform and build options are detected.


## Debugging Compilation Problems

### Missing or Wrong CMake

If `CMake` cannot be found, following can be defined in your environment.
Using those definitions in a `conda` activate script
(e.g.: `<CONDA_PREFIX>/etc/conda/activate.d/gcc.sh` or other shell script)
will avoid having to run this step manually each time.

``` shell
# use CONDA_PREFIX that is generated by 'conda activate <myenv>'
export CMAKE_EXECUTABLE="/usr/bin/cmake"
export CMAKE_PREFIX_PATH="${CONDA_PREFIX}"
```

### Failed to compute shorthash

This error can sometime occur when attempting to find CUDA libraries.
(see: https://github.com/pytorch/pytorch/issues/53350)

Simply define the following in your environment:

``` shell
export CUDA_NVRTC_LIB="<CUDA_PATH>/include/nvrtc.h"
```

Where `<CUDA_PATH>` is the same as matched references in `CMake` (e.g.: `/usr/local/cuda-11.2` if using `CUDA 11.2`).

## Debugging Runtime Errors

### ImportError `generic_type` with Unknown Reference

Whenever an error in a similar form as the following occurs:

``` python
ImportError: generic_type: type "EfficientNet" referenced unknown base type "torch::nn::Module"
```

It means that `torch` was not properly imported *before* importing the library extensions.
Because linking is done dynamically against `torch`, it must always be imported first as follows:

``` python
import torch
import crim_libtorch_extensions
```

### Unrecognized Symbol Error

The most common cause of unrecognized symbols at runtime is due to missing linking libraries or inconsistent references.
Most of the automatic resolution of Python bindings against PyTorch definitions is done inplace and as needed.
Therefore, those missing links will be showed only at runtime.

You must make sure that the imported `torch` package (before importing the extensions) are indeed the
same libraries that were used to compile the extensions. There are high chances of incompatibilities and missing
symbols between compilation from different sources. For example, if the library linked against during `import torch`
refers to a package installed via `pip` or `conda`, but extensions were compiled from source [PyTorch][pytorch]
libraries, they will most probably not match.

If the above situation occurs, uninstall any `pip` or `conda` installation. Then, build and install
[PyTorch from Sources](https://github.com/pytorch/pytorch#from-source) following their directives.
This should be not much more than preparing your environment variables to find references and define custom options,
and then call `python setup.py install`. Finally, rebuild and install the extensions with the source libraires using
the same command inside this repository.
